{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# machine learning\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "MODEL_PATH = 'Careless Response Detection/models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rr_data = pd.read_csv('data_mod_resp.csv', sep = ';')\n",
    "rr_data.columns = rr_data.columns.str.replace('17_', '')\n",
    "current_rate = ''\n",
    "current_model = ''\n",
    "current_data_type = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitter\n",
    "def modelFit(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    if(model=='rf'):\n",
    "\n",
    "        param_prefix = 'RandomForestClassifier'.lower()+('__')\n",
    "        new_params = { \n",
    "            param_prefix+'n_estimators': [200, 500],\n",
    "            param_prefix+'max_features': ['sqrt', 'log2'],\n",
    "            param_prefix+'max_depth' : [8,10,12,14,16],\n",
    "            param_prefix+'criterion' :['gini', 'entropy']\n",
    "        }\n",
    "        imba_pipeline = make_pipeline(SMOTE(random_state=1132), RandomForestClassifier(random_state=1132))\n",
    "\n",
    "    elif(model=='gbm'):\n",
    "\n",
    "        param_prefix = 'GradientBoostingClassifier'.lower()+('__')\n",
    "        new_params = { \n",
    "            param_prefix+'n_estimators': [200, 500],\n",
    "            param_prefix+'learning_rate': np.arange(0.5,2.0,0.5),\n",
    "            param_prefix+'max_depth' : [8,10,12,14,16],\n",
    "            param_prefix+'subsample' : np.arange(0.7,1.0,0.1)\n",
    "        }\n",
    "        imba_pipeline = make_pipeline(SMOTE(random_state=1132), GradientBoostingClassifier(random_state=1132))\n",
    "\n",
    "    elif(model=='svm'):\n",
    "\n",
    "        new_params = { }\n",
    "        imba_pipeline = make_pipeline(SMOTE(random_state=1132), SVC(random_state=1132))\n",
    "\n",
    "    elif(model=='knn'):\n",
    "\n",
    "        param_prefix = 'KNeighborsClassifier'.lower()+('__')\n",
    "        new_params = {             \n",
    "            param_prefix+'n_neighbors': np.arange(5,14,2),\n",
    "            param_prefix+'weights' : ['uniform', 'distance']\n",
    "        }\n",
    "        imba_pipeline = make_pipeline(SMOTE(random_state=1132), KNeighborsClassifier())\n",
    "\n",
    "    elif(model=='nnet'):\n",
    "\n",
    "        param_prefix = 'MLPClassifier'.lower()+('__')\n",
    "        new_params = { }\n",
    "        imba_pipeline = make_pipeline(SMOTE(random_state=1132), MLPClassifier(random_state=1132))\n",
    "\n",
    "    grid_imba = GridSearchCV(imba_pipeline, param_grid=new_params, cv=10, scoring='recall',\n",
    "                            return_train_score=True)\n",
    "    return grid_imba.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = \"C:/Program Files/R/R-4.2.2\"\n",
    "\n",
    "\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Choosing a CRAN Mirror\n",
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "\n",
    "# Installing required packages\n",
    "packages = ('bartMachine', 'caret', 'reticulate', 'data.table', 'dplyr')\n",
    "utils.install_packages(StrVector(packages))\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BARTCreator(X_train, y_train, file_name):\n",
    "    \n",
    "    robjects.r('''\n",
    "options(java.parameters = \"-Xmx2g\")\n",
    "            f <- function(X, y, verbose=TRUE) {\n",
    "\n",
    "                if (verbose) {\n",
    "                    cat(\"R code for BART started\\n\")\n",
    "                }\n",
    "\n",
    "        y <- ifelse(y, 'zeros', 'ones')\n",
    "        y <- factor(y)\n",
    "        y <- relevel(y, ref = 'zeros')\n",
    "\n",
    "            bart_machine_cv = bartMachine::bartMachineCV(X, y, serialize = TRUE,  k_folds = 10,\n",
    "                                                        num_tree_cvs = 150, k_cvs = c(1,2,3))\n",
    "            }\n",
    "\n",
    "            ''')\n",
    "\n",
    "    r_f = robjects.globalenv['f']\n",
    "    model = r_f(X_train, y_train)\n",
    "    # robjects.r.saveRDS(model, file_name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cr_type in ['cr_all', 'cr_human', 'cr_computer']:\n",
    "    current_data_type  = cr_type\n",
    "    cr_data = pd.read_csv(cr_type+'.csv', sep = ';')\n",
    "    cr_data.columns = cr_data.columns.str.replace('17_', '')\n",
    "    for rate in [5, 10, 15, 20]:\n",
    "        current_rate = str(rate)\n",
    "        rr_rate = (1- (rate/100))\n",
    "        cr_sample_num = int((rr_data.shape[0]/rr_rate)-rr_data.shape[0])\n",
    "        cr_sample = cr_data.sample(n=cr_sample_num, replace=True)\n",
    "        merged_data=pd.concat([rr_data,cr_sample],axis=0)\n",
    "        merged_data= merged_data.sample(frac=1) \n",
    "        y = merged_data[\"Careless\"]\n",
    "        X = merged_data.drop(\"Careless\", axis=1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,shuffle=True)\n",
    "        for model in ['bart']:\n",
    "            current_model = model\n",
    "            file_name = MODEL_PATH+current_model+'_'+current_rate+'_'+current_data_type\n",
    "            print('-----------------Running ' + file_name + '-----------------')\n",
    "            start = time.time()\n",
    "            if(model=='bart'):\n",
    "                fitted_model = BARTCreator(X_train, y_train, file_name)\n",
    "            else:\n",
    "                fitted_model = modelFit(model, X_train, X_test, y_train, y_test)\n",
    "            end = time.time()\n",
    "            \n",
    "            print('Finished ' + file_name + ' - Time taken: ' + str(end-start))\n",
    "            pickle.dump(fitted_model, open(file_name+'.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Evaluate model performance using confusion matrix\n",
    "with open(MODEL_PATH + 'bart_20_cr_all.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "y_pred=pd.DataFrame(robjects.r.predict(model, X_test))\n",
    "y_pred[y_pred >= 0.5] = 1\n",
    "y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "AUROC = np.round(roc_auc_score(y_test, y_pred), 2)\n",
    "\n",
    "print(\"false positive rate - \",round(fpr[1],2))\n",
    "print(\"true positive rate - \",round(tpr[1],2))\n",
    "print(\"AUROC - \",round(AUROC,2))\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
